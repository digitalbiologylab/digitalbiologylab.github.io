[
  {
    "objectID": "supportus.html",
    "href": "supportus.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "We use buy me a coffee.\n\n\n\n\n\nThank you."
  },
  {
    "objectID": "posts/250310-phospho-dia/index.html",
    "href": "posts/250310-phospho-dia/index.html",
    "title": "Phosphorylation site report from a DIA-MS experiment",
    "section": "",
    "text": "Skowronek et al. 2022 reported a large difference between the performance of Spectronaut and DIA-NN. For DIA-MS-based phosphoproteomics, one of the issues was that it was not easy to extract a phosphosite report from the different processing tools. In Pham et al. 2024, we presented a software tool called sitereport in the Python package msproteomics to extract a phosphosite report for both Spectronaut and DIA-NN, allowing for a comparative assessment of their performances.\nWe are curious about the new number of phosphosites for the newly released DIA-NN 2.0.2!\nTo that end, we analyze the same dataset consisting of 4 timsTOF DIA-MS runs from Skowronek et al. by DIA-NN 2.0.2 using the same spectral library. The --export-quant switch is turned on. The result can be downloaded here.\nWe then convert the DIA-NN parquet output to a tab-delimited text format. This can be done in R as in our previous blogpost. Nevertheless, we have added a script in the latest release of the msproteomics package, version 1.1.0, for convenience. Note that installation of an additional Python package pyarrow is required for this step.\npython -m pip install pyarrow\n\ndiann_parquet_to_tsv -i report.parquet -o report.tsv\nThen, we continue the processing as before\nread_diann -o report_msproteomics.tsv -E Intensities -f uniprot-reviewed_yes_AND_organism__Homo_sapiens__Human___9606___.fasta report.tsv\n\nsitereport report_msproteomics.tsv\n\nThe Venn diagram shows the number of phosphosites returned by the three different software packages/versions and their overlaps. DIA-NN 2.0.2 detects considerably more phosphosites than DIA-NN 1.8.2 beta 27, 23440 sites versus 19730 sites respectively. Note that the number of phosphosites includes multiplicities as in MaxQuant and Spectronaut. Please refer to our publication for detail.\n\nOther filtering\nAccording the discussion here, another filtering for DIA-NN consists of\n\n\nboth lib & global q-value filter at 0.5 (that is 50%)\nboth lib & global peptidoform q-value filter at 0.5\nrun-specific q-value filter 0.01\nrun-specific PEP filter 0.01\nrun-specific peptidoform q-value filter 0.01\nif using channels, run-specific channel q-value filter 0.01\n\n\nWe can apply this filtering on the DIA-NN report prior to creating the tab-delimited text file. We will use R for this step\nraw &lt;- arrow::read_parquet(\"report.parquet\")\n\nraw$Intensities &lt;- paste(raw$Fr.0.Quantity, raw$Fr.1.Quantity, raw$Fr.2.Quantity, \n                        raw$Fr.3.Quantity, raw$Fr.4.Quantity, raw$Fr.5.Quantity, \n                        raw$Fr.6.Quantity, raw$Fr.7.Quantity, raw$Fr.8.Quantity, \n                        raw$Fr.9.Quantity, raw$Fr.10.Quantity, raw$Fr.11.Quantity, \n                        sep = \";\")\n\nselected &lt;- raw$Lib.Q.Value &lt;= 0.5 & \n            raw$Global.Q.Value &lt;= 0.5 & \n            raw$Lib.Peptidoform.Q.Value &lt;= 0.5 & \n            raw$Global.Peptidoform.Q.Value &lt;= 0.5 &\n            raw$Q.Value &lt;= 0.01 & raw$PEP &lt;= 0.05 & \n            raw$Peptidoform.Q.Value &lt;= 0.01\n\nwrite.table(raw[selected, ], \"report-filtered.tsv\", sep = \"\\t\", \n            row.names = FALSE, quote = FALSE)\nThen we process the filtered data as before, but without the default filters. This can be done by setting the values ‘none’ to the filters as follows.\nread_diann -o report_msproteomics-filtered.tsv -E Intensities -f uniprot-reviewed_yes_AND_organism__Homo_sapiens__Human___9606___.fasta report-filtered.tsv\n\nsitereport report_msproteomics-filtered.tsv -output_site new_filtering_site.tsv -output_peptide  new_filtering_peptide.tsv -site_filter_double_less none none -site_filter_double_greater none none -peptide_filter_double_less none none\n\nThe number of sites with the new filtering is slightly less than the default msproteomics filtering. The a large number of overlapping sites suggests that the two filtering approaches are highly similar. Note that this is much higher than the number reported by DIA-NN site report, report.phosphosites_90.tsv (14441 sites) and report.phosphosites_99.tsv (12467 sites). This is most likely because msproteomics sitereport uses phosphorylation multiplicities."
  },
  {
    "objectID": "posts/250215-zippy/index.html",
    "href": "posts/250215-zippy/index.html",
    "title": "One command to zip them all",
    "section": "",
    "text": "To upload timsTOF data to ProteomeXchange, we have to create a single file for each .d data folder. One can zip each folder by right-click and send-to a compressed zipped folder. For tens or hundreds of folders, that process is tedious.\nI previously used tar in a Unix command line for file in *.d; do tar cvf $file.tar $file; done. But that requires a Unix-like system like Cygwin installed on your Windows machine.\nIt turns out that tar is also available on Windows 10/11! If you want to zip all timsTOF .d data folders, open a command prompt, go to the folder containing all the .d folders, and type\nfor /d %v in (*.d) do tar.exe -a -c -v -f \"%v.zip\" \"%v\"\nYou can place the command in a batch file (use %% in place of %). Or just download zippy.bat to where the .d data folders are and run it.\nEnjoy."
  },
  {
    "objectID": "members.html",
    "href": "members.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "Pham Viet Thang, PhD (Amsterdam UMC & Vietnam National University, topic: computational genomics and proteomics, AI, machine learning, life sciences).\nNguyen Van Vinh, PhD (Vietnam National University, topic: AI, natural language processing, deep learning, health care)\nDo Minh Duc (VNU, topic: protein kinase and substrates)\nToan Nguyen (VNU, topic: phosphoproteomics)\nPham Huy Chau Long (VNU, github, topic: generative AI, protein quantification)\nTran Phuc Khang (VNU, topic: Effects of neutral losses in data-independent acquisition mass spectrometry-based proteomics)\nDoan Van Phong (VNU, topic: encoding of phosphorylated peptides for deep neural networks)\n\n\nFormer members\n\nLe Gia Duc (2024, VinUni, internship at Amsterdam UMC, topic: protein quantification)\nCan Ha An (2024, VinUni, internship at Amsterdam UMC, topic: protein quantification)\nBui Huy Linh Phuc (2024, VinUni, internship at Amsterdam UMC, topic: protein quantification)"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "Bruderer DIA-MS data (MCP 2015) processed by DIA-NN 1.8.1\nPham, T. V. (2025). Bruderer DIA-MS data processed by DIA-NN 1.8.1. [Data set]. Zenodo https://doi.org/10.5281/zenodo.14823673\n\n\nSkowronek DIA-MS phosphoproteomics data (MCP 2022) processed by DIA-NN 2.0.2\nPham, T. V. (2025). A DIA-MS-based phosphoproteomics data processed by DIA-NN 2.0.2. [Data set]. Zenodo https://doi.org/10.5281/zenodo.15002613"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "Phosphorylation site report from a DIA-MS experiment\n\n\n\n\n\n\nphosphoproteomics\n\n\nDIA-MS\n\n\nmsproteomics\n\n\nsitereport\n\n\nscript\n\n\n\n\n\n\n\n\n\nMar 10, 2025\n\n\nThang V. Pham & Pham Huy Chau Long\n\n\n\n\n\n\n\n\n\n\n\n\nDIA-NN 2.0 and tsv file output\n\n\n\n\n\n\niq\n\n\nprotein quantification\n\n\nR\n\n\nscript\n\n\n\n\n\n\n\n\n\nMar 1, 2025\n\n\nThang V. Pham\n\n\n\n\n\n\n\n\n\n\n\n\nA Kruskal-Wallis test is added to ion\n\n\n\n\n\n\nion\n\n\nR\n\n\nscript\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 25, 2025\n\n\nThang V. Pham\n\n\n\n\n\n\n\n\n\n\n\n\nOne command to zip them all\n\n\n\n\n\n\nscript\n\n\n\n\n\n\n\n\n\nFeb 15, 2025\n\n\nThang V. Pham\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing DIA-NN 1.8.1 output\n\n\n\n\n\n\niq\n\n\nprotein quantification\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nThang V. Pham\n\n\n\n\n\n\n\n\n\n\n\n\nHello world\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nDec 28, 2024\n\n\nThang V. Pham\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "We develop and maintain computational methods to aid in the analysis of biological samples."
  },
  {
    "objectID": "posts/220301-parquet-tsv/index.html",
    "href": "posts/220301-parquet-tsv/index.html",
    "title": "DIA-NN 2.0 and tsv file output",
    "section": "",
    "text": "From version 2.0, DIA-NN stops producing output in the tab-delimited text format (.tsv). It uses the parquet data format. In our experiments, a .parquet file output is about 10 times smaller than the equivalent .tsv file. If your downstream processing tool requires a .tsv file as input, you can convert a .parquet file to .tsv file using the R package arrow.\nrequire(\"arrow\")\n# if the package \"arrow\" is not available, you can install it by \n# install.packages(\"arrow\") \n\nwrite.table(arrow::read_parquet(\"report.parquet\"), \"report.tsv\", \n            sep = \"\\t\", row.names = FALSE, quote = FALSE)\n\nDIA-MS quantification at the fragment level\nFor protein quantification using MS/MS fragments, one needs to switch on the --export-quant flag\n\n\n\nScreenshot of the DIA-NN 2.0.2 parameter box\n\n\nThe fragment intensities will be in the .parquet file columns Fr.0.Quantity, Fr.1.Quantity, and so on till Fr.11.Quantity. We can combine all quantitative information in a new column called Intensities as input to the iq R package.\nraw &lt;- arrow::read_parquet(\"report.parquet\")\n\nraw$Intensities = paste(raw$Fr.0.Quantity, raw$Fr.1.Quantity, raw$Fr.2.Quantity, \n                        raw$Fr.3.Quantity, raw$Fr.4.Quantity, raw$Fr.5.Quantity, \n                        raw$Fr.6.Quantity, raw$Fr.7.Quantity, raw$Fr.8.Quantity, \n                        raw$Fr.9.Quantity, raw$Fr.10.Quantity, raw$Fr.11.Quantity, sep = \";\")\n\nwrite.table(raw, \"report.tsv\", sep = \"\\t\", row.names = FALSE, quote = FALSE)\nWe can then process the resulting report.tsv file using iq.\niq::process_long_format(\"report.tsv\", \n                        output_filename = \"report-protein-group.txt\", \n                        sample_id = \"Run\",\n                        intensity_col = \"Intensities\",\n                        annotation_col = c(\"Protein.Ids\",\"Protein.Names\", \"Genes\"),\n                        filter_double_less = c(\"Q.Value\" = \"0.01\", \"PG.Q.Value\" = \"0.05\", \n                                               \"Lib.Q.Value\" = \"0.01\", \n                                               \"Lib.PG.Q.Value\" = \"0.01\"))\n\n\nA smaller tsv file\nYou can also just store necessary columns for iq processing, or filtering out fragments that will not be used, or both.\nraw &lt;- arrow::read_parquet(\"report.parquet\")\n\nraw$Intensities = paste(raw$Fr.0.Quantity, raw$Fr.1.Quantity, raw$Fr.2.Quantity, \n                        raw$Fr.3.Quantity, raw$Fr.4.Quantity, raw$Fr.5.Quantity, \n                        raw$Fr.6.Quantity, raw$Fr.7.Quantity, raw$Fr.8.Quantity, \n                        raw$Fr.9.Quantity, raw$Fr.10.Quantity, raw$Fr.11.Quantity, sep = \";\")\n\nselected &lt;- raw$Q.Value &lt; 0.01 & raw$PG.Q.Value &lt; 0.05 & \n            raw$Lib.Q.Value &lt; 0.01 & raw$Lib.PG.Q.Value &lt; 0.01\n\nraw &lt;- raw[selected, c(\"Run\", \"Protein.Group\", \"Precursor.Id\", \"Precursor.Normalised\",\n                       \"Protein.Ids\",\"Protein.Names\", \"Genes\", \"Intensities\")]\n\nwrite.table(raw, \"report-trimmed.tsv\", sep = \"\\t\", row.names = FALSE, quote = FALSE)\n\niq::process_long_format(\"report-trimmed.tsv\", \n                    output_filename = \"report-protein-group-trimmed.txt\", \n                    sample_id = \"Run\",\n                    intensity_col = \"Intensities\",\n                    annotation_col = c(\"Protein.Ids\",\"Protein.Names\", \"Genes\"),\n                    filter_double_less = NULL)\n\n\nOpen a big tsv file with Excel\nUsually not a good idea. A big .tsv file is not suitable for Excel. I often look at the head of the file to check if the headers are ok.\n# On Unix-like systems\nhead report.tsv &gt; report-head.tsv\n# On Window PowerShell\ngc report.tsv -head 10 &gt; report-head.tsv\nThe resulting file report-head.tsv can be easily opened by Excel for examination."
  },
  {
    "objectID": "posts/250206-diann-1.8.2/index.html",
    "href": "posts/250206-diann-1.8.2/index.html",
    "title": "Processing DIA-NN 1.8.1 output",
    "section": "",
    "text": "We processed the Bruderer15 dataset (Bruderer et al., MCP 2015) using DIA-NN 1.8.1 (Demichev et al., Nature Methods 2020) with the switch --report-lib-info turned on. The switch gives an extra column Fragment.Info to test iq’s new feature. Usually, the user does not need to turn it on.\nDownload DIA-NN output report.zip and unzip the file to obtain the long format ouput report.tsv (Pham, Zenodo 2025, https://doi.org/10.5281/zenodo.14823673).\nA protein group report for downstream analysis can be obtained with a single statement in R\nlibrary(iq)\nprocess_long_format(\"report.tsv\", output_filename = \"report-pg.tsv\")\nAs an aside, usually the user wants to include additional annotation columns in the final report. This is possible by specifying the annotation_col parameter.\nprocess_long_format(\"report.tsv\", output_filename = \"report-pg-annotated.tsv\",\n                    annotation_col = c(\"Protein.Names\", \"Genes\"))\nAlso, by default, we filter the report at 1% run-sepcific FDR at both precursor level and protein group level. To filter global FDR (available with a recent version of DIA-NN), use the parameter filter_double_less.\nprocess_long_format(\"report.tsv\", output_filename = \"report-pg-global.tsv\", \n                    annotation_col = c(\"Protein.Names\", \"Genes\"),\n                    filter_double_less = c(\"Global.Q.Value\" = \"0.01\", \"Global.PG.Q.Value\" = \"0.01\"))  \nWe continue with loading the result file report-pg.tsv to check the quantitative values of the spike-in proteins. For convenience, we will use the spike-in protein names instead of the protein group names.\npg &lt;- read.delim(\"report-pg.tsv\")\nrownames(pg) &lt;- pg$Protein.Group\n\nspike_ins &lt;- c(\"P02754\", \"P80025\", \"P00921\", \"P00366\", \"P02662\", # mix 1\n               \"P61823\", \"P02789\", \"P12799\", \"P02676\", \"P02672\", # mix 2\n               \"P02666\", \"P68082\")                               # mix 3\n\n# change rownames to spike_ins names\nfor (i in 1: length(spike_ins)) {\n    rownames(pg)[grep(spike_ins[i], rownames(pg))] &lt;- spike_ins[i]\n}\n\nMix 1\nHere is the ground truth for proteins in Mix 1 (P02754, P80025, P00921, P00366, P02662). Each sample was measured in triplicate.\n\n\n\nSample\nrelative\nfmol/ul\n\n\n\n\n1\n1\n1.5\n\n\n2\n1.1\n1.65\n\n\n3\n1.21\n1.815\n\n\n4\n1.33\n1.995\n\n\n5\n10\n15\n\n\n6\n11.01\n16.515\n\n\n7\n12.11\n18.165\n\n\n8\n13.33\n19.995\n\n\n\nmatplot(t(pg[spike_ins[1:5], 2:25]), type = 'b', col = 1:5 , pch=19, lwd = 3,\n        ylab=\"log2 MaxLFQ\", main = \"Mix 1\", xlab = \"8 samples x 3 replicates\")\nlegend(\"topleft\", legend = spike_ins[1:5], col = 1:5, pch=19, bty = \"n\")\n\nWe see that the triplicates are consistent and the spikeins in first 4 samples (12 runs) are about 10 fold down as expected (log2(10) ~ 3.3).\n\n\nMix 2\nHere is the ground truth of proteins in Mix 2 (P61823, P02789, P12799, P02676, P02672).\n\n\n\nSample\nrelative\nfmol/ul\n\n\n\n\n1\n200\n100\n\n\n2\n125.99\n62.995\n\n\n3\n79.37\n39.685\n\n\n4\n50\n25\n\n\n5\n4\n2\n\n\n6\n2.52\n1.26\n\n\n7\n1.59\n0.795\n\n\n8\n1\n0.5\n\n\n\nmatplot(t(pg[spike_ins[6:10], 2:25]), type = 'b', col = 1:5 , pch=19, lwd = 3,\n        ylab=\"log2 MaxLFQ\", main = \"Mix 2\", xlab = \"8 samples x 3 replicates\")\nlegend(\"topright\", legend = spike_ins[6:10], col = 1:5, pch=19, bty = \"n\")\n\nIn this mix, proteins in the first 4 samples are higher. Fold change between sample 1 and sample 5 is 50, which is approximately 5.6 in log2 space.\n\n\nMix 3\nHere is the ground truth of proteins in Mix 3 (P02666, P68082).\n\n\n\nSample\nrelative\nfmol/ul\n\n\n\n\n1\n1\n0.05\n\n\n2\n4\n0.2\n\n\n3\n16\n0.8\n\n\n4\n64\n3.2\n\n\n5\n256\n12.8\n\n\n6\n1024\n51.2\n\n\n7\n4096\n204.8\n\n\n8\n16384\n819.2\n\n\n\n\nmatplot(t(pg[spike_ins[11:12], 2:25]), type = 'b', col = 1:6 , pch=19, lwd = 3,\n        ylab=\"log2 MaxLFQ\", main = \"Mix 3\", xlab = \"8 samples x 3 replicates\")\nlegend(\"topleft\", legend = spike_ins[11:12], col = 1:2, pch=19, bty = \"n\")\n\nIn this mix, the protein concentration increases 4 fold from sample 1 to sample 8. Thus, we expect a staircase shape with an increase of 2 in log2 space.\n\n\nRandom 12 proteins\nset.seed(0)\nmatplot(t(pg[sample(1:nrow(pg), 12), 2:25]), type = 'b', col = 1:6 , pch=19, lwd = 3,\n        ylab=\"log2 MaxLFQ\", main = \"Random 12 proteins\", xlab = \"8 samples x 3 replicates\")\n\nThis is a set of 12 random proteins in the background. High abundance proteins show a consistent pattern while lower abundance proteins exhibits more variation and missing data, which is expected from mass spectrometry-based proteomics data."
  },
  {
    "objectID": "posts/250224-kruskal-wallis/index.html",
    "href": "posts/250224-kruskal-wallis/index.html",
    "title": "A Kruskal-Wallis test is added to ion",
    "section": "",
    "text": "I’ve added a script to ion to perform a Kruskal-Wallis test for each row in a data matrix (ion$kruskal_test_3g). This statistical test is a non-parametric test and can be seen as a multi-group generalization of the Mann-Whitney test (or Wilcoxon test) for two-group comparisons.\nA non-parametric test is robust and applicable to various types of data including spectral count data and intensity-based quantification in proteomics. Nevertheless, it requires a larger number of samples than a parametric test such as the beta-binomial test or the t-test. I expect that 10 samples per group are sufficient. I’ve read somewhere that 15 should be the minimum. But I have also seen studies using a non-parametric test for 5 samples per group. In short, there is no hard rule that I am aware of."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Digital Biology Lab",
    "section": "",
    "text": "We are maintaining a number of open-source software packages\n\niq\ncountdata\nmsproteomics\naiproteomics\nion\n\nLong-term maintenance of published software is not supported by research funding. If you find these software packages useful, please consider supporting us."
  }
]